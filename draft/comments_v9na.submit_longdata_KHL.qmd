---
title: "Longitudinal analysis of Shigella"
format: 
  pdf:
    number-sections: true
    number-depth: 2
    number-offset: [0, 0]
editor: visual
output:
  pdf_document:
    orientation: landscape
---

## Introduction

```{r setup, include=FALSE,echo=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}

devtools::load_all()

devtools::install_github("ucd-serg/serocalculator")
library(serocalculator)
library(tidyverse)
library(runjags)
#library(coda)
library(ggmcmc)
library(here)

library(gridExtra)
library(haven)
library(knitr)
library(plotly)
library(kableExtra)
library(tidyr)
library(arsenal)
library(dplyr)
library(forcats)
library(huxtable)
library(magrittr)
library(parameters)
library(kableExtra)
library(ggplot2)
library(ggeasy)
library(scales)
library(plotly)
library(patchwork)
library(tidyverse)
library(gtsummary)
library(readxl)
```



```{r, echo=FALSE, message=FALSE}
#model file
#file.mod <- here::here()  %>% fs::path("inst/extdata/model.jags.r")
file.mod <- here::here()  %>% fs::path("inst/extdata/model.jags.2.r")
```

- Model file from this path


```{r, echo=FALSE, message=FALSE}
#long data - CHOLERA
 dL <- 
   read_csv(here::here()  %>% fs::path("inst/extdata/cholera_data_compiled_050324.csv")) %>%
   group_by(index_id, antigen_iso) %>%# Group data by individual
   arrange(visit) %>%  # Sort data by visit within each group
   mutate(visit_num = rank(visit, ties.method = "first")) %>%
   ungroup()
 
```

- In this data manipulation, 'group_by' did sorting and creating new variables will be done separately for each combination of index_id and antigen_iso. 'mutate(visit_num = rank(visit, ties.method = "first"))' created new column visit_num and the first occurrence gets the lower rank. Essentially, visit_num will represent the order of visits within each group.


## Body


```{r, echo=FALSE, message=FALSE}
#subset data for checking
 dL_sub <- dL %>%
   filter(index_id %in% sample(unique(index_id), 20))
```

In this code,

- We extracts 20 random unique index_ids from dL.

- Then we filters the rows of dL to keep only those where the index_id is one of the 20 randomly selected index_ids.

- The resulting filtered dataframe is assigned to dL_sub.


```{r, echo=FALSE, message=FALSE}
# Construct the path to "prep_data.r" using here
prep_data_path <- here::here("R", "prep_data.r")
prep_priors_path <- here::here("R", "prep_priors.R")
 
# Source the file to load the prep_data function
source(prep_data_path)
source(prep_priors_path)
```

- To use 'prep_data' and 'prep_priors' functions, we need this step


```{r, echo=FALSE, message=FALSE}
#prepare data for modeline
 longdata <- prep_data(dL_sub)
 
```
In this 'prep_data' function,

- The function first checks if the input data includes the necessary columns: antigen_iso (for antigen types) and visit_num (for visit numbers). If not, it stops and shows an error. (Column check)

- It then collects all unique visit numbers, antigen types, and subject IDs from the data. Using these, it sets up arrays to store information like when visits occurred and antibody levels for each subject. It also adds a dummy subject to the data for Bayesian inference. (Data extraction and setup)

- The function fills these arrays with the actual data, such as the time of each visit and the antibody levels (log-transformed to handle very small values). For the dummy subject, it adds predefined visit times and sets the antibody levels as missing. (Data population)


```{r, echo=FALSE, message=FALSE}
priors <- prep_priors(max_antigens = longdata$n_antigen_isos)
```
In this prep_priors function,

- Initialize Arrays: The function sets up several arrays to store prior information for the model parameters. It creates:

  - mu.hyp: Means of the prior distributions.
  - prec.hyp: Precision matrices for the prior distributions.
  - omega: Another set of precision matrices.
  - wishdf: Degrees of freedom for a Wishart distribution.
  - prec.logy.hyp: Precision parameters for the log-transformed antibody levels.

- Fill Arrays: It then fills these arrays with predefined values. These values are used to specify prior beliefs about the model parameters, like their means and how much they vary.

- Return Results: Finally, the function returns these arrays in a list so they can be used later in your analysis.




```{r, echo=FALSE, message=FALSE}
#inputs for jags model
 nchains <- 4;                # nr of MC chains to run simultaneously
 nadapt  <- 100;             # nr of iterations for adaptation
 nburnin <- 100;            # nr of iterations to use for burn-in
 nmc     <- 100;             # nr of samples in posterior chains
 niter   <- 100;            # nr of iterations for posterior sample
 nthin   <- round(niter/nmc); # thinning needed to produce nmc from niter

tomonitor <- c("y0", "y1", "t1", "alpha", "shape");
```

- Inputs for the JAGS Model

  - nchains: Number of Markov Chains (MC) to run simultaneously. More chains can help check for convergence and ensure a thorough exploration of the posterior distribution.
  
  - nadapt: Number of iterations for adaptation. During this phase, the sampler tunes its parameters to improve sampling efficiency.
  
  - nburnin: Number of iterations to use for burn-in. These initial samples are discarded to allow the chain to reach the stationary distribution, reducing the effect of starting values.
  
  - nmc: Number of samples to collect from the posterior distribution after burn-in and thinning. These samples are used for estimating the posterior distribution.
  
  - niter: Number of iterations for the posterior sample. This is the total number of iterations after the burn-in period.
  
  - nthin: Thinning interval to reduce autocorrelation. It determines how many iterations to skip between collected samples. Calculated as round(niter / nmc) to achieve the desired number of posterior samples.
  
  - tomonitor: Variables to monitor during sampling. These are the parameters of interest (e.g., "y0", "y1", "t1", "alpha", "shape") for which the posterior distributions will be estimated.



```{r, echo=FALSE, message=FALSE}
#This handles the seed to reproduce the results 
 initsfunction <- function(chain){
   stopifnot(chain %in% (1:4)); # max 4 chains allowed...
   .RNG.seed <- (1:4)[chain];
   .RNG.name <- c("base::Wichmann-Hill","base::Marsaglia-Multicarry",
                  "base::Super-Duper","base::Mersenne-Twister")[chain];
   return(list(".RNG.seed"=.RNG.seed,".RNG.name"=.RNG.name));
 }

```

Aim: This function sets the initial random number generator (RNG) seed and RNG type for each chain. This ensures that the results can be reproduced by starting with the same random numbers each time.

- The function first checks if the input chain number is between 1 and 4. If not, it stops with an error. This ensures only up to 4 chains are allowed. (Function input)

- Each chain is assigned a unique seed from the numbers 1 to 4. This seed determines the starting point for the random number generator. (Seed assignment)

- Each chain is also assigned a different type of RNG from a predefined list of four types (Wichmann-Hill, Marsaglia-Multicarry, Super-Duper, Mersenne-Twister). (RNG type assignment)

- The function returns a list containing the RNG seed and the RNG type for the given chain. (Return values)



```{r, echo=FALSE, message=FALSE}
 jags.post <- run.jags(model=file.mod,data=c(longdata, priors),
                       inits=initsfunction,method="parallel",
                       adapt=nadapt,burnin=nburnin,thin=nthin,sample=nmc,
                       n.chains=nchains,
                       monitor=tomonitor,summarise=FALSE);

```


Aim: This code runs a JAGS model to perform Bayesian analysis using the provided model, data, and settings. It collects samples from the posterior distribution of the model parameters.

- Steps:

  - Model File: You provide file.mod containing your JAGS model code.
  - Data: You use longdata and priors as input data.
  - Initial Values: Use initsfunction to set reproducible starting points.
  - Run in Parallel: Set method to "parallel" to speed up the process.
  - Adaptation: Run 100 adaptation iterations (nadapt=100).
  - Burn-in: Run 100 burn-in iterations (nburnin=100).
  - Thinning: Keep every 1st sample (nthin=1).
  - Sampling: Collect 100 samples from each chain (nmc=100).
  - Chains: Run 4 chains (nchains=4).
  - Monitor Parameters: Keep track of y0, y1, t1, alpha, shape.
  - Summary: Do not summarize results immediately (summarise=FALSE).

- Diagram
Model File (file.mod)
       |
       v
Data (longdata + priors)
       |
       v
Initialize Chains (initsfunction)
       |
       v
Run in Parallel (method="parallel")
       |
       v
Adaptation (nadapt)
       |
       v
Burn-in (nburnin)
       |
       v
Thinning (nthin)
       |
       v
Sampling (nmc)
       |
       v
Chains (nchains)
       |
       v
Monitor Parameters (tomonitor)
       |
       v
Do Not Summarize (summarise=FALSE)


```{r, echo=FALSE, message=FALSE}
 mcmc_list <- as.mcmc.list(jags.post)
 
```

Aim: The as.mcmc.list function converts the output from a JAGS model run (jags.post) into a format that is easier to work with for analysis and visualization. Specifically, it converts the output into an MCMC list, which is a standard format for storing Markov Chain Monte Carlo (MCMC) samples in R.

- Steps:

  - Input: The JAGS model run output (jags.post) contains the MCMC samples.
  - Convert: The as.mcmc.list function converts jags.post into an mcmc.list.
  - Output: The result is an mcmc.list object, where each element is the samples from one of the chains.
  
  
```{r, echo=FALSE, message=FALSE}
 mcmc_df <- ggs(mcmc_list)
```

Aim: The ggs function converts MCMC samples into a data frame format that is specifically designed for easy visualization using ggplot2. It takes the structured samples in the mcmc.list format and reshapes them into a long data frame format.

- Steps:

  - Input: The mcmc_list object contains the MCMC samples organized by chain.
  - Convert: The ggs function reshapes this into a data frame.
  - Output: The result is mcmc_df, a data frame with rows for each sample, columns for parameter names, chain numbers, iterations, and sample values.

```{r, echo=FALSE, message=FALSE}
 wide_predpar_df <- mcmc_df %>%
   mutate(
     parameter = sub("^(\\w+)\\[.*", "\\1", Parameter),  # Extract base parameter name
     index_id = as.numeric(sub("^\\w+\\[(\\d+),.*", "\\1", Parameter)),  # Extract index ID
     antigen_iso = as.numeric(sub("^\\w+\\[\\d+,(\\d+).*", "\\1", Parameter))  # Extract antigen type
   ) %>%
   mutate(
     index_id = factor(index_id, labels = c(unique(dL_sub$index_id), "newperson")),  # Convert index_id to factor with labels
     antigen_iso = factor(antigen_iso, labels = unique(dL_sub$antigen_iso))  # Convert antigen_iso to factor with labels
   ) %>%
   filter(index_id == "newperson")  # Keep only rows for "newperson"
   select(-Parameter)  # Remove the original Parameter column
   pivot_wider(names_from = "parameter", values_from = "value")  # Reshape data to wide format
   rowwise()  # Process each row independently
   droplevels()  # Remove unused factor levels
   ungroup()  # Remove grouping
   rename(r = shape)  # Rename column from shape to r
```


Aim: This code processes the MCMC samples data frame (mcmc_df) to extract specific parameter values for a "newperson" and reshapes it into a wide format. The final output is a data frame where each row contains the parameter values for this "newperson".

- Steps:

  - Initial Data Frame: You start with mcmc_df, which contains MCMC samples with columns like Parameter, value, Chain, and Iteration.
  
  - Mutate: Extract the base parameter name (parameter), the index ID (index_id), and the antigen type (antigen_iso) from the Parameter column.
  
  - Filter: Keep only the rows where index_id is "newperson".
  
  - Select: Remove the original Parameter column, as we have extracted its components into new columns.
  
  - Pivot Wider: Convert the data from a long format (many rows, few columns) to a wide format (few rows, many columns), where each parameter type becomes a separate column.
  
  - Rowwise and Ungroup: Ensure each row is processed independently, then remove any grouping to simplify further operations.
  
  - Rename: Rename the column shape to r for clarity or consistency.



```{r, echo=FALSE, message=FALSE}
## For using serocaculator package

# Assuming wide_predpar_df is your data frame
curve_params <- wide_predpar_df

# Set class and attributes for serocalculator
class(curve_params) <- c("curve_params", class(curve_params))
antigen_isos <- unique(curve_params$antigen_iso)
attr(curve_params, "antigen_isos") <- antigen_isos

# Plot longitudinal antibody decay
plot.long <- autoplot(curve_params)
print(plot.long)
```

This code leverages the serocalculator functions to compute and visualize antibody decay curves.

- Set Class and Attributes:

  - The curve_params data frame is assigned a class curve_params, and antigen_isos are set as an attribute. This prepares the data for plotting using serocalculator.
  
- Plot Longitudinal Antibody Decay:

  - autoplot(curve_params) generates a plot showing the antibody decay curves based on the provided model parameters.

The autoplot() function from the serocalculator package is designed to visualize the antibody levels for each antigen, likely generating plots that show the trends over time based on your posterior samples.


```{r, echo=FALSE, message=FALSE}
# Define the antibody calculation function
ab <- function(t, y0, y1, t1, alpha, shape) {
  beta <- log(y1/y0) / t1
  if (t <= t1) {
    yt <- y0 * exp(beta * t)
  } else {
    yt <- (y1^(1 - shape) - (1 - shape) * alpha * (t - t1))^(1 / (1 - shape))
  }
  return(yt)
}

# Generate time points
tx2 <- 10^seq(-1, 3, 0.025)

# Prepare data frame with time points
dT <- data.frame(t = tx2) %>%
  mutate(ID = 1:n()) %>%
  pivot_wider(names_from = ID, values_from = t, names_prefix = "time") %>%
  slice(rep(1:n(), each = nrow(wide_predpar_df)))

# Combine data and calculate antibody levels
serocourse.full <- cbind(wide_predpar_df, dT) %>%
  pivot_longer(cols = starts_with("time"), values_to = "t") %>%
  select(-name) %>%
  rowwise() %>%
  mutate(res = ab(t, y0, y1, t1, alpha, r)) %>%
  ungroup()

# Save the full serocourse data
write_csv(serocourse.full, "serocourse_full.csv")

# Summarize the serocourse data
serocourse.med <- serocourse.full %>%
  group_by(antigen_iso, t) %>%
  summarise(res.med = quantile(res, 0.5),
            res.low = quantile(res, 0.025),
            res.high = quantile(res, 0.975)) %>%
  pivot_longer(names_to = "quantile", cols = c("res.med", "res.low", "res.high"), names_prefix = "res.", values_to = "res")

# Save the summarized data
write_csv(serocourse.med, "serocourse_med.csv")

# Plot the summarized data
serocourse_plot <- ggplot(serocourse.med, aes(x = t, y = res, color = quantile)) +
  geom_line() +
  facet_wrap(~ antigen_iso) +
  scale_x_log10() +
  labs(title = "Longitudinal Antibody Decay with Uncertainty Intervals",
       x = "Time (log scale)",
       y = "Antibody Level")

print(serocourse_plot)
```

Aim: The overall purpose of these steps is to take your posterior samples from the JAGS model, calculate the antibody levels over a defined time period, and then summarize and visualize these levels to understand the longitudinal antibody decay.

- Predict Antibody Dynamics: Use model parameters to predict how antibody levels change over time.

- Quantify Uncertainty: Provide a measure of uncertainty in these predictions through quantiles.

- Visualize Results: Create clear visualizations that can be interpreted and communicated effectively.

- Steps:

  - Define Antibody Calculation Function: ab(t, y0, y1, t1, alpha, shape): This function calculates the antibody level at any given time point t using the parameters y0, y1, t1, alpha, and shape derived from your model. This is crucial because it allows you to translate the parameters into meaningful antibody levels over time.
  
  - Generate Time Points:Variable (tx2) creates a sequence of time points (from 0.1 to 1000) over which you want to evaluate the antibody levels. These time points ensure that you can plot the decay curve smoothly and comprehensively across a reasonable time span.
  
  - Prepare Data Frame with Time Points: Data Frame (dT) step involves creating a data frame that includes these time points and replicating them for each row in your parameter data. This preparation is necessary for evaluating the antibody levels at each time point for each parameter set from your posterior samples.
  
  - Combine Data and Calculate Antibody Levels: Data Frame (serocourse.full) combines the parameters from your posterior samples with the time points and calculates the corresponding antibody levels using the ab function. This step generates a detailed dataset of predicted antibody levels over time for each sample.
  
  - Summarize the Serocourse Data: Data Frame (serocourse.med) step summarizes the full dataset by calculating the median, lower (2.5%), and upper (97.5%) quantiles of the antibody levels at each time point. This summarization is important to visualize the central tendency and the uncertainty (confidence intervals) in your antibody decay predictions.
  
  - Plot the Summarized Data: The final plot shows the median antibody levels with uncertainty intervals (quantiles) over time for each antigen type. This visualization is key for interpreting the antibody decay dynamics and understanding how antibody levels change over time for different antigens, including the uncertainty in these predictions.
  


By following these steps, we ensure a robust and detailed analysis of our longitudinal antibody data, leveraging the strengths of Bayesian modeling to account for uncertainty and variability in our predictions.



```{r, echo=FALSE, message=FALSE}

```


```{r, echo=FALSE, message=FALSE}

```


